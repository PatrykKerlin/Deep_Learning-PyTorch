{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DUDL_data_datasetLoader.ipynb",
   "provenance": [
    {
     "file_id": "1t1AgKE-GpPPUcjGZyTF_Ie1Q9XWA3xn-",
     "timestamp": 1618172332728
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyMDTrf0kN4swdushiJqB9Kn"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Data matrices and loaders\n",
    "### LECTURE: Anatomy of a torch dataset and dataloader\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202305"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeuAheYyhdZw",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.425916662Z",
     "start_time": "2024-01-13T11:07:41.140804870Z"
    }
   },
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFv_cmvApLb0"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aykKFgznOako",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.434752227Z",
     "start_time": "2024-01-13T11:07:42.429170997Z"
    }
   },
   "source": [
    "# create some data in numpy\n",
    "\n",
    "nObservations = 100\n",
    "nFeatures = 20\n",
    "\n",
    "data = np.random.randn(nObservations,nFeatures)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y_tZ1ymVp0Sf",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.439383666Z",
     "start_time": "2024-01-13T11:07:42.434364113Z"
    }
   },
   "source": [
    "# Convert to pytorch tensor\n",
    "dataT = torch.tensor( data ) \n",
    "\n",
    "# print out some information\n",
    "print('Numpy data:')\n",
    "print(type(data))\n",
    "print(data.shape) # numpy -> .shape\n",
    "print(data.dtype)\n",
    "print(' ')\n",
    "\n",
    "print('Tensor data:')\n",
    "print(type(dataT))\n",
    "print(dataT.size()) # torch -> .size()\n",
    "print(dataT.dtype)\n",
    "print(' ')"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy data:\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 20)\n",
      "float64\n",
      " \n",
      "Tensor data:\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([100, 20])\n",
      "torch.float64\n",
      " \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WlSTQeZ2nDDR",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.444832949Z",
     "start_time": "2024-01-13T11:07:42.441040810Z"
    }
   },
   "source": [
    "# Sometimes you need to convert data types\n",
    "\n",
    "dataT2 = torch.tensor( data ).float()\n",
    "print(dataT2.dtype)\n",
    "\n",
    "# \"long\" is for ints\n",
    "dataT3 = torch.tensor( data ).long()\n",
    "print(dataT3.dtype)\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u5fGd4h8mI8a",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.498972023Z",
     "start_time": "2024-01-13T11:07:42.450764741Z"
    }
   },
   "source": [
    "# Convert tensor into PyTorch Datasets\n",
    "\n",
    "# dataset = TensorDataset(data) # not a tensor!\n",
    "dataset = TensorDataset(dataT)\n",
    "\n",
    "# dataset is a two-element tuple comprising data,labels\n",
    "dataset.tensors[0]"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.9336,  1.8326,  0.9296,  ..., -0.5260,  1.5012,  0.2124],\n        [ 0.7782, -0.1300,  0.8250,  ..., -1.1243, -1.8103,  1.0482],\n        [ 0.3972,  0.4827,  0.6433,  ...,  0.6698,  0.1595,  0.1241],\n        ...,\n        [-0.4870,  1.2634,  0.5562,  ..., -1.7627, -1.9108, -2.2675],\n        [-1.0357, -1.3072,  0.2334,  ...,  0.7512,  0.5838,  0.0678],\n        [-0.0784,  0.3506,  0.4014,  ...,  0.6987, -0.7107,  1.4232]],\n       dtype=torch.float64)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wpvxvxBloej3",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.500376102Z",
     "start_time": "2024-01-13T11:07:42.498638424Z"
    }
   },
   "source": [
    "# Let's try again with labels\n",
    "labels = torch.ceil(torch.linspace(.01,4,nObservations))\n",
    "\n",
    "# transform to an actual matrix (column vector)\n",
    "labels = labels.reshape(( len(labels),1 ))\n",
    "# print( labels )\n",
    "\n",
    "# now make another dataset\n",
    "dataset = TensorDataset(dataT,labels)\n",
    "print( dataset.tensors[0].size() )\n",
    "print( dataset.tensors[1].size() )\n",
    "\n",
    "# for comparison\n",
    "print( np.shape(np.random.randint(5,size=nObservations)) )"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 20])\n",
      "torch.Size([100, 1])\n",
      "(100,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ-JsNQGpIKT"
   },
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5_kahYcanxBg",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.501600867Z",
     "start_time": "2024-01-13T11:07:42.498872650Z"
    }
   },
   "source": [
    "# create a dataloader object\n",
    "batchsize = 25\n",
    "dataloader = DataLoader(dataset,batch_size=batchsize)#,shuffle=True,drop_last=True)\n",
    "\n",
    "dataloader.dataset.tensors[0].size()"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 20])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xu7BF_OTqDj0",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.502820773Z",
     "start_time": "2024-01-13T11:07:42.499062339Z"
    }
   },
   "source": [
    "# sizes of each batch\n",
    "for dat,labs in dataloader:\n",
    "  print('BATCH INFO:')\n",
    "  print(dat.size())\n",
    "  print(labs.size())\n",
    "  print(' ')"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oLkY18PZq-G3",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.503733478Z",
     "start_time": "2024-01-13T11:07:42.499209711Z"
    }
   },
   "source": [
    "# inspect the labels\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1.]])\n",
      " \n",
      "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2.]])\n",
      " \n",
      "tensor([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "         3., 3., 3., 3., 3., 3., 3.]])\n",
      " \n",
      "tensor([[4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
      "         4., 4., 4., 4., 4., 4., 4.]])\n",
      " \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zyeJ6mjjre6p",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.572877500Z",
     "start_time": "2024-01-13T11:07:42.499495905Z"
    }
   },
   "source": [
    "# try again with shuffling (shuffling happens during iterations)\n",
    "# dataloader = DataLoader(dataset,batch_size=batchsize,shuffle=True)\n",
    "\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1.]])\n",
      " \n",
      "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2.]])\n",
      " \n",
      "tensor([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "         3., 3., 3., 3., 3., 3., 3.]])\n",
      " \n",
      "tensor([[4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
      "         4., 4., 4., 4., 4., 4., 4.]])\n",
      " \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S236TLLury42",
    "ExecuteTime": {
     "end_time": "2024-01-13T11:07:42.573435814Z",
     "start_time": "2024-01-13T11:07:42.546403245Z"
    }
   },
   "source": [
    "# To get only one batch (e.g., for testing)\n",
    "\n",
    "dat,labs = next(iter(dataloader))\n",
    "\n",
    "labs"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ]
}
